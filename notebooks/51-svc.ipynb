{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter  # noqa: F401\n",
    "import torch\n",
    "from cuml.svm import LinearSVC\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file found\n"
     ]
    }
   ],
   "source": [
    "embedding_exists = None\n",
    "df_reddit = None\n",
    "\n",
    "try:\n",
    "    df_reddit = pd.read_parquet(\"../data/processed/reddit_posts_embedded.parquet\")\n",
    "    embedding_exists = True\n",
    "    print(\"Embedding file found\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Embedding file not found, cleaning up and re-embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>depth</th>\n",
       "      <th>edited</th>\n",
       "      <th>score</th>\n",
       "      <th>search_query</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>test</th>\n",
       "      <th>fraud</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yxu5tv</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>magus-21</td>\n",
       "      <td>Secretly lending customer funds, market-making...</td>\n",
       "      <td>2022-11-17 16:10:14</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1597</td>\n",
       "      <td>Safe Moon</td>\n",
       "      <td>r/CryptoCurrency</td>\n",
       "      <td>\"DYOR\" is worthless. You can't \"Do Your Own Re...</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>634</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.4334820508956909, -0.4628458321094513, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id parent_id    author  \\\n",
       "0  yxu5tv      <NA>  magus-21   \n",
       "\n",
       "                                                body             created  \\\n",
       "0  Secretly lending customer funds, market-making... 2022-11-17 16:10:14   \n",
       "\n",
       "   depth edited  score search_query         subreddit  \\\n",
       "0     -1    NaT   1597    Safe Moon  r/CryptoCurrency   \n",
       "\n",
       "                                               title  \\\n",
       "0  \"DYOR\" is worthless. You can't \"Do Your Own Re...   \n",
       "\n",
       "                                                 url  num_comments  test  \\\n",
       "0  https://www.reddit.com/r/CryptoCurrency/commen...           634  True   \n",
       "\n",
       "   fraud                                          embedding  \n",
       "0   True  [-0.4334820508956909, -0.4628458321094513, -0....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not embedding_exists:\n",
    "    df_reddit = pd.read_parquet(\"../data/processed/reddit_posts.parquet\")\n",
    "    df_reddit[\"created\"] = pd.to_datetime(df_reddit[\"created\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df_reddit[\"edited\"] = pd.to_datetime(df_reddit[\"edited\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "df_reddit.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>fraud</th>\n",
       "      <th>test</th>\n",
       "      <th>max_market_cap_e9</th>\n",
       "      <th>start_date</th>\n",
       "      <th>subreddits</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bitcoin</th>\n",
       "      <td>BTC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2010-07-14</td>\n",
       "      <td>[CryptoCurrency, CryptoMoonShots, CryptoMarket...</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        symbol  fraud   test  max_market_cap_e9 start_date  \\\n",
       "name                                                         \n",
       "Bitcoin    BTC  False  False             1800.0 2010-07-14   \n",
       "\n",
       "                                                subreddits end_date  \n",
       "name                                                                 \n",
       "Bitcoin  [CryptoCurrency, CryptoMoonShots, CryptoMarket...      NaT  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coins = pd.read_json(\"../data/raw/coins.json\")\n",
    "df_coins[\"start_date\"] = pd.to_datetime(df_coins[\"start_date\"], format=\"ISO8601\")\n",
    "df_coins[\"end_date\"] = pd.to_datetime(df_coins[\"end_date\"], format=\"ISO8601\")\n",
    "df_coins = df_coins.set_index(\"name\")\n",
    "\n",
    "df_coins.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coin_info_row(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get coin information for a given row.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the dataframe containing a search_query column.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The coin information corresponding to the search_query.\n",
    "\n",
    "    \"\"\"\n",
    "    return df_coins.loc[row.search_query]\n",
    "\n",
    "\n",
    "def is_comment_valid_row(row: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a comment is valid based on the coin's start and end dates.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the dataframe containing created and edited columns.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the comment is valid, False otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "    coin = get_coin_info_row(row)\n",
    "\n",
    "    comment_date = row.edited if pd.notna(row.edited) else row.created\n",
    "    start_date_valid = comment_date >= coin[\"start_date\"]\n",
    "    end_date_valid = comment_date <= coin[\"end_date\"] if pd.notna(coin[\"end_date\"]) else True\n",
    "\n",
    "    return start_date_valid and end_date_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not embedding_exists:\n",
    "    df_reddit[\"test\"] = df_reddit.swifter.apply(get_coin_info_row, axis=1)[\"test\"]\n",
    "    df_reddit[\"fraud\"] = df_reddit.swifter.apply(get_coin_info_row, axis=1)[\"fraud\"]\n",
    "    df_reddit[\"valid\"] = df_reddit.swifter.apply(is_comment_valid_row, axis=1)\n",
    "\n",
    "    df_reddit = df_reddit[df_reddit[\"valid\"]]\n",
    "    df_reddit = df_reddit.drop(columns=[\"valid\"])\n",
    "    df_reddit = df_reddit.reset_index(drop=True)\n",
    "\n",
    "    df_reddit.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_query\n",
       "Bitcoin       142163\n",
       "Chainlink      72875\n",
       "Ethereum       72409\n",
       "Safe Moon      69352\n",
       "Cosmos         57082\n",
       "Avalanche      35673\n",
       "FTX Token      21656\n",
       "THORChain      18772\n",
       "Terra Luna      8683\n",
       "BitForex        2611\n",
       "BeerCoin         805\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit[\"search_query\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not embedding_exists:\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert_embedder = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "    # Pre-fetch texts as numpy array for efficient slicing\n",
    "    texts = df_reddit[\"body\"].values\n",
    "    embeddings = []\n",
    "\n",
    "    EMBEDDING_BATCH_SIZE = 2**7\n",
    "    print(f\"Embedding batch size: {EMBEDDING_BATCH_SIZE}\")\n",
    "\n",
    "    # Process batches\n",
    "    for i in tqdm(range(0, len(texts), EMBEDDING_BATCH_SIZE)):\n",
    "        batch_texts = texts[i : i + EMBEDDING_BATCH_SIZE]\n",
    "        with torch.no_grad():\n",
    "            tokens = bert_tokenizer.batch_encode_plus(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=True,\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = bert_embedder(**tokens)[\"pooler_output\"].cpu()\n",
    "            embeddings.extend(outputs.tolist())\n",
    "\n",
    "    df_reddit[\"embedding\"] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not embedding_exists:\n",
    "    df_reddit.to_parquet(\"../data/processed/reddit_posts_embedded.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_reddit[~df_reddit[\"test\"]]\n",
    "test_df = df_reddit[df_reddit[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svc_model(\n",
    "    data: pd.DataFrame,\n",
    "    penalty: str = \"l2\",\n",
    "    max_iter: int = 1000,\n",
    "    linesearch_max_iter: int = 100,\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Train a linear SVC model.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The data to train the model on.\n",
    "        penalty (str): The penalty to use for the model.\n",
    "        max_iter (int): The maximum number of iterations.\n",
    "        linesearch_max_iter (int): The maximum number of iterations for the line search.\n",
    "        verbose (bool): Whether to print the per-coin-results.\n",
    "\n",
    "    Returns:\n",
    "        dict_accuracy (dict): A dictionary containing the accuracy for each coin.\n",
    "\n",
    "    \"\"\"\n",
    "    dict_accuracy = {}\n",
    "    for i, val_coin in enumerate(data[\"search_query\"].unique()):\n",
    "        # Get the fitting and validation splits\n",
    "        fit_df = data[data[\"search_query\"] != val_coin]\n",
    "        val_df = data[data[\"search_query\"] == val_coin]\n",
    "\n",
    "        # Shuffle the fitting split\n",
    "        fit_df = fit_df.sample(frac=1, random_state=42)\n",
    "\n",
    "        # Create the embeddings\n",
    "        fit_embeddings = np.array(fit_df.embedding.to_list())\n",
    "        val_embeddings = np.array(val_df.embedding.to_list())\n",
    "\n",
    "        # Create the labels\n",
    "        fit_labels = np.array(fit_df[\"fraud\"].to_list()) * 1\n",
    "        val_labels = np.array(val_df[\"fraud\"].to_list()) * 1\n",
    "\n",
    "        # Create the model\n",
    "        model = LinearSVC(\n",
    "            class_weight=\"balanced\",\n",
    "            penalty=penalty,\n",
    "            max_iter=max_iter,\n",
    "            linesearch_max_iter=linesearch_max_iter,\n",
    "        )\n",
    "        model.fit(fit_embeddings, fit_labels)\n",
    "\n",
    "        # Predict the validation set\n",
    "        predictions = model.predict(val_embeddings)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = (predictions == val_labels).mean()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\"\"\n",
    "            Coin left out: {val_coin}\n",
    "            Correct Label: {val_df['fraud'].iloc[0]}\n",
    "            Predicted as Fraud: {int(predictions.sum())}\n",
    "            Predicted as Not Fraud: {int(len(predictions) - predictions.sum())}\n",
    "            Mean prediction: {predictions.mean():.4f}\n",
    "            Accuracy: {accuracy:.4f}\n",
    "            \"\"\")\n",
    "\n",
    "        dict_accuracy[val_coin] = accuracy\n",
    "\n",
    "    return dict_accuracy\n",
    "\n",
    "\n",
    "def random_search_svc(data: pd.DataFrame, n_iter: int = 10, verbose: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a random search for hyperparameter optimization.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The data to train the model on.\n",
    "        n_iter (int): The number of iterations to run.\n",
    "        verbose (bool): Whether to print the per-coin-results.\n",
    "\n",
    "    Returns:\n",
    "        dict_params (dict): A dictionary containing the best hyperparameters.\n",
    "        dict_accuracy (dict): A dictionary containing the accuracy for each coin for the best hyperparameters.\n",
    "\n",
    "    \"\"\"\n",
    "    dict_params = {}\n",
    "    dict_accuracy = {}\n",
    "    best_accuracy = 0\n",
    "    rng = np.random.default_rng()\n",
    "    for i in range(n_iter):\n",
    "        penalty = rng.choice([\"l1\", \"l2\"]).item()\n",
    "        max_iter = rng.integers(1, 1000)\n",
    "        linesearch_max_iter = rng.integers(1, 100)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\"\"\n",
    "    Iteration: {i}\n",
    "    Training with:\n",
    "    Penalty: {penalty}, Max Iter: {max_iter}, Line Search Max Iter: {linesearch_max_iter}\n",
    "            \"\"\")\n",
    "\n",
    "        accuracy = train_svc_model(\n",
    "            data,\n",
    "            penalty=penalty,\n",
    "            max_iter=max_iter,\n",
    "            linesearch_max_iter=linesearch_max_iter,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        mean_accuracy = np.mean(list(accuracy.values()))\n",
    "        if mean_accuracy > best_accuracy and 0 not in accuracy.values():\n",
    "            best_accuracy = mean_accuracy\n",
    "            dict_params = {\n",
    "                \"penalty\": penalty,\n",
    "                \"max_iter\": max_iter,\n",
    "                \"linesearch_max_iter\": linesearch_max_iter,\n",
    "            }\n",
    "            dict_accuracy = accuracy\n",
    "\n",
    "    return dict_params, dict_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_params, dict_accuracy = random_search_svc(train_df, n_iter=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_params, dict_accuracy\n",
    "\n",
    "# see output below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "({'penalty': 'l1',\n",
    "  'max_iter': np.int64(61),\n",
    "  'linesearch_max_iter': np.int64(96)},\n",
    " {'Chainlink': np.float64(0.5154442538593482),\n",
    "  'Avalanche': np.float64(0.5282706809071286),\n",
    "  'THORChain': np.float64(0.5071382910718091),\n",
    "  'Bitcoin': np.float64(0.5453599037724303),\n",
    "  'Terra Luna': np.float64(0.36473569042957504),\n",
    "  'BeerCoin': np.float64(0.5950310559006211),\n",
    "  'BitForex': np.float64(0.6495595557257756)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [14:24:32.471354] QWL-QN: max iterations reached\n",
      "[W] [14:24:32.471459] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
      "\n",
      "    Coin left out: Safe Moon\n",
      "    Correct Label: True\n",
      "    Predicted as Fraud: 27387\n",
      "    Predicted as Not Fraud: 41965\n",
      "    Mean prediction: 0.3949\n",
      "    Accuracy: 0.3949\n",
      "    \n",
      "\n",
      "    Coin left out: FTX Token\n",
      "    Correct Label: True\n",
      "    Predicted as Fraud: 9275\n",
      "    Predicted as Not Fraud: 12381\n",
      "    Mean prediction: 0.4283\n",
      "    Accuracy: 0.4283\n",
      "    \n",
      "\n",
      "    Coin left out: Cosmos\n",
      "    Correct Label: False\n",
      "    Predicted as Fraud: 28121\n",
      "    Predicted as Not Fraud: 28961\n",
      "    Mean prediction: 0.4926\n",
      "    Accuracy: 0.5074\n",
      "    \n",
      "\n",
      "    Coin left out: Ethereum\n",
      "    Correct Label: False\n",
      "    Predicted as Fraud: 25399\n",
      "    Predicted as Not Fraud: 47010\n",
      "    Mean prediction: 0.3508\n",
      "    Accuracy: 0.6492\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "fit_df = train_df.sample(frac=1, random_state=42)\n",
    "\n",
    "fit_embeddings = np.array(fit_df.embedding.to_list())\n",
    "fit_labels = np.array(fit_df.fraud.to_list()) * 1\n",
    "\n",
    "model = LinearSVC(\n",
    "    class_weight=\"balanced\",\n",
    "    penalty=\"l1\",\n",
    "    max_iter=61,\n",
    "    linesearch_max_iter=96,\n",
    ")\n",
    "model.fit(fit_embeddings, fit_labels)\n",
    "\n",
    "for i, coin in enumerate(test_df[\"search_query\"].unique()):\n",
    "    coin_df = test_df[test_df[\"search_query\"] == coin]\n",
    "    coin_embeddings = np.array(coin_df.embedding.to_list())\n",
    "    coin_labels = np.array(coin_df[\"fraud\"].to_list()) * 1\n",
    "\n",
    "    predictions = model.predict(coin_embeddings)\n",
    "    accuracy = (predictions == coin_labels).mean()\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Coin left out: {coin}\n",
    "    Correct Label: {coin_df['fraud'].iloc[0]}\n",
    "    Predicted as Fraud: {int(predictions.sum())}\n",
    "    Predicted as Not Fraud: {int(len(predictions) - predictions.sum())}\n",
    "    Mean prediction: {predictions.mean():.4f}\n",
    "    Accuracy: {accuracy:.4f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Coin left out: Safe Moon\n",
    "    Correct Label: True\n",
    "    Predicted as Fraud: 27387\n",
    "    Predicted as Not Fraud: 41965\n",
    "    Mean prediction: 0.3949\n",
    "    Accuracy: 0.3949\n",
    "    \n",
    "\n",
    "    Coin left out: FTX Token\n",
    "    Correct Label: True\n",
    "    Predicted as Fraud: 9275\n",
    "    Predicted as Not Fraud: 12381\n",
    "    Mean prediction: 0.4283\n",
    "    Accuracy: 0.4283\n",
    "    \n",
    "\n",
    "    Coin left out: Cosmos\n",
    "    Correct Label: False\n",
    "    Predicted as Fraud: 28121\n",
    "    Predicted as Not Fraud: 28961\n",
    "    Mean prediction: 0.4926\n",
    "    Accuracy: 0.5074\n",
    "    \n",
    "\n",
    "    Coin left out: Ethereum\n",
    "    Correct Label: False\n",
    "    Predicted as Fraud: 25399\n",
    "    Predicted as Not Fraud: 47010\n",
    "    Mean prediction: 0.3508\n",
    "    Accuracy: 0.6492"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
